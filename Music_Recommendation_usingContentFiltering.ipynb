{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1RWddhuEHt9",
        "outputId": "21b22c0b-1dca-4bb4-9061-4060a4eda671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WLjFWjyU-kAx",
        "outputId": "bfd4d4d0-f418-476b-b528-7247e7295c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "88/88 [==============================] - 6s 5ms/step - loss: 7.9590 - accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 7.9425 - accuracy: 7.1048e-04\n",
            "Epoch 3/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 7.8725 - accuracy: 0.0110\n",
            "Epoch 4/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 7.4686 - accuracy: 0.0220\n",
            "Epoch 5/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 6.5659 - accuracy: 0.0568\n",
            "Epoch 6/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 5.2495 - accuracy: 0.1812\n",
            "Epoch 7/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 3.8430 - accuracy: 0.3393\n",
            "Epoch 8/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 2.7232 - accuracy: 0.4519\n",
            "Epoch 9/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 1.9991 - accuracy: 0.5119\n",
            "Epoch 10/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 1.5627 - accuracy: 0.5524\n",
            "Epoch 11/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 1.3054 - accuracy: 0.5783\n",
            "Epoch 12/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 1.1451 - accuracy: 0.5826\n",
            "Epoch 13/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 1.0373 - accuracy: 0.5861\n",
            "Epoch 14/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.9577 - accuracy: 0.6053\n",
            "Epoch 15/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.9070 - accuracy: 0.6082\n",
            "Epoch 16/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.8680 - accuracy: 0.6153\n",
            "Epoch 17/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.8339 - accuracy: 0.6089\n",
            "Epoch 18/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.8057 - accuracy: 0.6174\n",
            "Epoch 19/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.7749 - accuracy: 0.6281\n",
            "Epoch 20/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.7556 - accuracy: 0.6327\n",
            "Epoch 21/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.7420 - accuracy: 0.6306\n",
            "Epoch 22/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7273 - accuracy: 0.6412\n",
            "Epoch 23/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.7141 - accuracy: 0.6327\n",
            "Epoch 24/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.7029 - accuracy: 0.6394\n",
            "Epoch 25/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.6451\n",
            "Epoch 26/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6817 - accuracy: 0.6472\n",
            "Epoch 27/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.6430\n",
            "Epoch 28/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.6583\n",
            "Epoch 29/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6529 - accuracy: 0.6572\n",
            "Epoch 30/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6572\n",
            "Epoch 31/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6600\n",
            "Epoch 32/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6285 - accuracy: 0.6647\n",
            "Epoch 33/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6650\n",
            "Epoch 34/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.6750\n",
            "Epoch 35/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6107 - accuracy: 0.6639\n",
            "Epoch 36/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.6054 - accuracy: 0.6707\n",
            "Epoch 37/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.5945 - accuracy: 0.6828\n",
            "Epoch 38/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5906 - accuracy: 0.6782\n",
            "Epoch 39/200\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5861 - accuracy: 0.6824\n",
            "Epoch 40/200\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.5862 - accuracy: 0.6792\n",
            "Epoch 41/200\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.5795 - accuracy: 0.6796\n",
            "Epoch 42/200\n",
            "88/88 [==============================] - 1s 14ms/step - loss: 0.5731 - accuracy: 0.6860\n",
            "Epoch 43/200\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5684 - accuracy: 0.6845\n",
            "Epoch 44/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5615 - accuracy: 0.6863\n",
            "Epoch 45/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5585 - accuracy: 0.6920\n",
            "Epoch 46/200\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5533 - accuracy: 0.6970\n",
            "Epoch 47/200\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5523 - accuracy: 0.6902\n",
            "Epoch 48/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5498 - accuracy: 0.6952\n",
            "Epoch 49/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5458 - accuracy: 0.6888\n",
            "Epoch 50/200\n",
            "44/88 [==============>...............] - ETA: 0s - loss: 0.4623 - accuracy: 0.7585"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b34d571f471e>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Use the model to recommend similar songs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the data and reset index\n",
        "data = pd.read_csv('songs_dataset.csv')\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "# Remove rows with NaN values in Lyrics and Genre\n",
        "data = data.dropna(subset=['Lyrics', 'Genre', 'Chords']).reset_index(drop=True)\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Tokenize and stem the lyrics\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "data['stemmed_lyrics'] = data['Lyrics'].apply(lambda x: ' '.join([stemmer.stem(word.lower()) for word in nltk.word_tokenize(x) if word.lower() not in stop_words]))\n",
        "\n",
        "# Concatenate the stemmed lyrics and the chords\n",
        "data['lyrics_and_chords'] = data['stemmed_lyrics'] + ' ' + data['Chords']\n",
        "\n",
        "# Vectorize the lyrics and chords\n",
        "vectorizer = TfidfVectorizer()\n",
        "lc_matrix = vectorizer.fit_transform(data['lyrics_and_chords'])\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(lc_matrix.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "model.add(Dense(lc_matrix.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(lc_matrix.toarray(), np.identity(lc_matrix.shape[0]), epochs=200, batch_size=32)\n",
        "\n",
        "# Use the model to recommend similar songs\n",
        "title = 'WAGON WHEEL'\n",
        "df_title = data[data['Song Title'] == title]\n",
        "if not df_title.empty:\n",
        "    idx = df_title.index[0]\n",
        "    song_vector = lc_matrix[idx].toarray()\n",
        "    scores = model.predict(song_vector)\n",
        "    top_n_indices = np.argsort(scores[0])[::-1][1:11]\n",
        "    recommendations_df = data.loc[top_n_indices, ['Song Title', 'Chords', 'Genre']]\n",
        "    print(recommendations_df)\n",
        "else:\n",
        "    print(\"The song title is not found in the dataset.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAlKdJF4PyQW",
        "outputId": "c31d4f32-935e-4fcc-8895-a750353016d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.29.0-py3-none-any.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp (from gradio)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.1 (from gradio)\n",
            "  Downloading gradio_client-0.2.4-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.13.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson (from gradio)\n",
            "  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.1->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.1->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette<0.27.0,>=0.26.1 (from fastapi->gradio)\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=ccd078ebdedf1a0202f86b30fbdb9a490f5c978a44e906197c89a367cb4efdf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, multidict, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, aiosignal, httpx, fastapi, aiohttp, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 fastapi-0.95.1 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.29.0 gradio-client-0.2.4 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.14.1 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 multidict-6.0.4 orjson-3.8.12 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.26.1 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kWulWyZd-qBo",
        "outputId": "e1d31f63-b155-4fd5-ec3f-ff0afbb1c2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "88/88 [==============================] - 2s 5ms/step - loss: 7.9591 - accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 7.9437 - accuracy: 3.5524e-04\n",
            "Epoch 3/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 7.8898 - accuracy: 0.0046\n",
            "Epoch 4/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 7.5517 - accuracy: 0.0092\n",
            "Epoch 5/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 6.7659 - accuracy: 0.0327\n",
            "Epoch 6/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 5.5820 - accuracy: 0.1194\n",
            "Epoch 7/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 4.2174 - accuracy: 0.2742\n",
            "Epoch 8/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 3.0253 - accuracy: 0.4210\n",
            "Epoch 9/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 2.1914 - accuracy: 0.4991\n",
            "Epoch 10/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 1.6784 - accuracy: 0.5428\n",
            "Epoch 11/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 1.3695 - accuracy: 0.5613\n",
            "Epoch 12/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 1.1794 - accuracy: 0.5755\n",
            "Epoch 13/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 1.0492 - accuracy: 0.5869\n",
            "Epoch 14/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.9708 - accuracy: 0.5972\n",
            "Epoch 15/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.9089 - accuracy: 0.6021\n",
            "Epoch 16/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.8655 - accuracy: 0.6021\n",
            "Epoch 17/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.8311 - accuracy: 0.6114\n",
            "Epoch 18/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.7997 - accuracy: 0.6249\n",
            "Epoch 19/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.7767 - accuracy: 0.6277\n",
            "Epoch 20/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.7573 - accuracy: 0.6281\n",
            "Epoch 21/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.7340 - accuracy: 0.6384\n",
            "Epoch 22/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.7239 - accuracy: 0.6369\n",
            "Epoch 23/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.7081 - accuracy: 0.6426\n",
            "Epoch 24/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.6472\n",
            "Epoch 25/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.6558\n",
            "Epoch 26/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.6551\n",
            "Epoch 27/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.6519\n",
            "Epoch 28/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.6545 - accuracy: 0.6586\n",
            "Epoch 29/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.6427 - accuracy: 0.6611\n",
            "Epoch 30/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.6362 - accuracy: 0.6632\n",
            "Epoch 31/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.6288 - accuracy: 0.6739\n",
            "Epoch 32/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.6233 - accuracy: 0.6693\n",
            "Epoch 33/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.6188 - accuracy: 0.6703\n",
            "Epoch 34/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.6079 - accuracy: 0.6760\n",
            "Epoch 35/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.6001 - accuracy: 0.6813\n",
            "Epoch 36/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5960 - accuracy: 0.6753\n",
            "Epoch 37/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5935 - accuracy: 0.6831\n",
            "Epoch 38/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.5829 - accuracy: 0.6803\n",
            "Epoch 39/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5785 - accuracy: 0.6874\n",
            "Epoch 40/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.5786 - accuracy: 0.6821\n",
            "Epoch 41/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.5723 - accuracy: 0.6853\n",
            "Epoch 42/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5679 - accuracy: 0.6863\n",
            "Epoch 43/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5630 - accuracy: 0.6924\n",
            "Epoch 44/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.5592 - accuracy: 0.6863\n",
            "Epoch 45/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.6917\n",
            "Epoch 46/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.5489 - accuracy: 0.6956\n",
            "Epoch 47/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.6913\n",
            "Epoch 48/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.5414 - accuracy: 0.6938\n",
            "Epoch 49/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.5394 - accuracy: 0.6973\n",
            "Epoch 50/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7020\n",
            "Epoch 51/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7005\n",
            "Epoch 52/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7002\n",
            "Epoch 53/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.6906\n",
            "Epoch 54/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.6970\n",
            "Epoch 55/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7023\n",
            "Epoch 56/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7023\n",
            "Epoch 57/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7044\n",
            "Epoch 58/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7037\n",
            "Epoch 59/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7037\n",
            "Epoch 60/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7091\n",
            "Epoch 61/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7012\n",
            "Epoch 62/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7123\n",
            "Epoch 63/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7087\n",
            "Epoch 64/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7073\n",
            "Epoch 65/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7119\n",
            "Epoch 66/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7094\n",
            "Epoch 67/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7144\n",
            "Epoch 68/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4869 - accuracy: 0.7126\n",
            "Epoch 69/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4848 - accuracy: 0.7151\n",
            "Epoch 70/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7094\n",
            "Epoch 71/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7140\n",
            "Epoch 72/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7126\n",
            "Epoch 73/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7101\n",
            "Epoch 74/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7140\n",
            "Epoch 75/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7044\n",
            "Epoch 76/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7151\n",
            "Epoch 77/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4695 - accuracy: 0.7169\n",
            "Epoch 78/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4667 - accuracy: 0.7179\n",
            "Epoch 79/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7172\n",
            "Epoch 80/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4629 - accuracy: 0.7165\n",
            "Epoch 81/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4602 - accuracy: 0.7197\n",
            "Epoch 82/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7226\n",
            "Epoch 83/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7172\n",
            "Epoch 84/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7194\n",
            "Epoch 85/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7137\n",
            "Epoch 86/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7204\n",
            "Epoch 87/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7197\n",
            "Epoch 88/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7197\n",
            "Epoch 89/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7197\n",
            "Epoch 90/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7197\n",
            "Epoch 91/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7176\n",
            "Epoch 92/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7211\n",
            "Epoch 93/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7204\n",
            "Epoch 94/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7208\n",
            "Epoch 95/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7293\n",
            "Epoch 96/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7290\n",
            "Epoch 97/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4383 - accuracy: 0.7222\n",
            "Epoch 98/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4364 - accuracy: 0.7261\n",
            "Epoch 99/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.7318\n",
            "Epoch 100/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.7247\n",
            "Epoch 101/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.7279\n",
            "Epoch 102/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4302 - accuracy: 0.7265\n",
            "Epoch 103/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4307 - accuracy: 0.7201\n",
            "Epoch 104/200\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4286 - accuracy: 0.7258\n",
            "Epoch 105/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.7261\n",
            "Epoch 106/200\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4256 - accuracy: 0.7286\n",
            "Epoch 107/200\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4258 - accuracy: 0.7243\n",
            "Epoch 108/200\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4235 - accuracy: 0.7286\n",
            "Epoch 109/200\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4202 - accuracy: 0.7353\n",
            "Epoch 110/200\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4217 - accuracy: 0.7261\n",
            "Epoch 111/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.7236\n",
            "Epoch 112/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7311\n",
            "Epoch 113/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7282\n",
            "Epoch 114/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7215\n",
            "Epoch 115/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7311\n",
            "Epoch 116/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.7314\n",
            "Epoch 117/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7325\n",
            "Epoch 118/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.7307\n",
            "Epoch 119/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7357\n",
            "Epoch 120/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7329\n",
            "Epoch 121/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7300\n",
            "Epoch 122/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7378\n",
            "Epoch 123/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.7357\n",
            "Epoch 124/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.7332\n",
            "Epoch 125/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.7375\n",
            "Epoch 126/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.7321\n",
            "Epoch 127/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4037 - accuracy: 0.7396\n",
            "Epoch 128/200\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4029 - accuracy: 0.7286\n",
            "Epoch 129/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.7290\n",
            "Epoch 130/200\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.4000 - accuracy: 0.7332\n",
            "Epoch 131/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.7314\n",
            "Epoch 132/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.7300\n",
            "Epoch 133/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.3971 - accuracy: 0.7321\n",
            "Epoch 134/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.7375\n",
            "Epoch 135/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.3967 - accuracy: 0.7371\n",
            "Epoch 136/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.3958 - accuracy: 0.7236\n",
            "Epoch 137/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.7407\n",
            "Epoch 138/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.7353\n",
            "Epoch 139/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.7329\n",
            "Epoch 140/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.7304\n",
            "Epoch 141/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.7325\n",
            "Epoch 142/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.7318\n",
            "Epoch 143/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.7368\n",
            "Epoch 144/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.7350\n",
            "Epoch 145/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.7403\n",
            "Epoch 146/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.7378\n",
            "Epoch 147/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.7336\n",
            "Epoch 148/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.7332\n",
            "Epoch 149/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.7304\n",
            "Epoch 150/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.7375\n",
            "Epoch 151/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.7353\n",
            "Epoch 152/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.7385\n",
            "Epoch 153/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.7385\n",
            "Epoch 154/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.7339\n",
            "Epoch 155/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.7321\n",
            "Epoch 156/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.7357\n",
            "Epoch 157/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.7371\n",
            "Epoch 158/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.7368\n",
            "Epoch 159/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.3782 - accuracy: 0.7378\n",
            "Epoch 160/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.3782 - accuracy: 0.7375\n",
            "Epoch 161/200\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3778 - accuracy: 0.7375\n",
            "Epoch 162/200\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 0.3745 - accuracy: 0.7385\n",
            "Epoch 163/200\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3764 - accuracy: 0.7410\n",
            "Epoch 164/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.3775 - accuracy: 0.7300\n",
            "Epoch 165/200\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3751 - accuracy: 0.7304\n",
            "Epoch 166/200\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3716 - accuracy: 0.7407\n",
            "Epoch 167/200\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3744 - accuracy: 0.7353\n",
            "Epoch 168/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.3707 - accuracy: 0.7417\n",
            "Epoch 169/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.3689 - accuracy: 0.7410\n",
            "Epoch 170/200\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.3704 - accuracy: 0.7396\n",
            "Epoch 171/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.7393\n",
            "Epoch 172/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.7421\n",
            "Epoch 173/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.7410\n",
            "Epoch 174/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.7361\n",
            "Epoch 175/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.7432\n",
            "Epoch 176/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.7357\n",
            "Epoch 177/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.7421\n",
            "Epoch 178/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.7375\n",
            "Epoch 179/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.7400\n",
            "Epoch 180/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.7428\n",
            "Epoch 181/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.7460\n",
            "Epoch 182/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.7439\n",
            "Epoch 183/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.7368\n",
            "Epoch 184/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.7407\n",
            "Epoch 185/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.7361\n",
            "Epoch 186/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.7393\n",
            "Epoch 187/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.7400\n",
            "Epoch 188/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.7407\n",
            "Epoch 189/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 0.7428\n",
            "Epoch 190/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.7375\n",
            "Epoch 191/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.7428\n",
            "Epoch 192/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3610 - accuracy: 0.7400\n",
            "Epoch 193/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.7396\n",
            "Epoch 194/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.3611 - accuracy: 0.7393\n",
            "Epoch 195/200\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.3587 - accuracy: 0.7346\n",
            "Epoch 196/200\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.7446\n",
            "Epoch 197/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.7414\n",
            "Epoch 198/200\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.7382\n",
            "Epoch 199/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.7410\n",
            "Epoch 200/200\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.7393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/outputs.py:128: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import gradio as gr\n",
        "\n",
        "# Load the data and reset index\n",
        "data = pd.read_csv('songs_dataset.csv')\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "# Remove rows with NaN values in Lyrics and Genre\n",
        "data = data.dropna(subset=['Lyrics', 'Genre', 'Chords']).reset_index(drop=True)\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Tokenize and stem the lyrics\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "data['stemmed_lyrics'] = data['Lyrics'].apply(lambda x: ' '.join([stemmer.stem(word.lower()) for word in nltk.word_tokenize(x) if word.lower() not in stop_words]))\n",
        "\n",
        "# Concatenate the stemmed lyrics and the chords\n",
        "data['lyrics_and_chords'] = data['stemmed_lyrics'] + ' ' + data['Chords']\n",
        "\n",
        "# Vectorize the lyrics and chords\n",
        "vectorizer = TfidfVectorizer()\n",
        "lc_matrix = vectorizer.fit_transform(data['lyrics_and_chords'])\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(lc_matrix.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(lc_matrix.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(lc_matrix.toarray(), np.identity(lc_matrix.shape[0]), epochs=10000, batch_size=32)\n",
        "\n",
        "# Define a function to get recommendations\n",
        "def get_recommendations(title):\n",
        "    df_title = data[data['Song Title'] == title.upper()]\n",
        "    if not df_title.empty:\n",
        "        idx = df_title.index[0]\n",
        "        song_vector = lc_matrix[idx].toarray()\n",
        "        scores = model.predict(song_vector)\n",
        "        top_n_indices = np.argsort(scores[0])[::-1][1:11]\n",
        "        recommendations_df = data.loc[top_n_indices, ['Song Title', 'Chords', 'Genre']]\n",
        "        return recommendations_df\n",
        "    else:\n",
        "        return \"The song title is not found in the dataset.\"\n",
        "\n",
        "# Define the inputs and outputs for the Gradio interface\n",
        "inputs = gr.inputs.Textbox(label=\"Enter a song in capital letters\")\n",
        "outputs = gr.outputs.Dataframe(type=\"pandas\", headers=[\"Song Title\", \"Chords\", \"Genre\"])\n",
        "\n",
        "\n",
        "# Create the Gradio interface\n",
        "title_recommender = gr.Interface(fn=get_recommendations, inputs=inputs, outputs=outputs, title=\"Song Recommender System\", description=\"Enter a song and get recommended songs!\")\n",
        "\n",
        "# Run the interface\n",
        "title_recommender.launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}